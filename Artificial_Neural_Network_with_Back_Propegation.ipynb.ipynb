{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from random import seed, uniform\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#load all of the data from csv files into nd arrays\n",
    "test_file = open(\"assets/testing10000.csv\")\n",
    "testing_array = np.loadtxt(test_file, delimiter=\",\")\n",
    "\n",
    "train_file = open(\"assets/training60000.csv\")\n",
    "training_array = np.loadtxt(train_file, delimiter= \",\")\n",
    "\n",
    "test_labels = open(\"assets/testing10000_labels.csv\")\n",
    "testing_labels = np.loadtxt(test_labels, delimiter= \",\")\n",
    "\n",
    "train_labels = open(\"assets/training60000_labels.csv\")\n",
    "training_labels = np.loadtxt(train_labels, delimiter= \",\")\n",
    "\n",
    "# NORMALIZE THE DATA - CRITICAL FIX\n",
    "training_array = training_array / 255.0\n",
    "testing_array = testing_array / 255.0\n",
    "\n",
    "# confirm sizes/ proper loading\n",
    "print(testing_array.shape)\n",
    "print(training_array.shape, \"\\n\")\n",
    "\n",
    "#represent target digits as vectors\n",
    "T0 = [0.99, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
    "T1 = [0.01, 0.99, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
    "T2 = [0.01, 0.01, 0.99, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
    "T3 = [0.01, 0.01, 0.01, 0.99, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
    "T4 = [0.01, 0.01, 0.01, 0.01, 0.99, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
    "T5 = [0.01, 0.01, 0.01, 0.01, 0.01, 0.99, 0.01, 0.01, 0.01, 0.01]\n",
    "T6 = [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.99, 0.01, 0.01, 0.01]\n",
    "T7 = [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.99, 0.01, 0.01]\n",
    "T8 = [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.99, 0.01]\n",
    "T9 = [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.99]\n",
    "\n",
    "actual = np.array([T0, T1, T2, T3, T4, T5, T6, T7, T8, T9])\n",
    "\n",
    "seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a random floating point value between range -0.5 and 0.5 (IMPROVED RANGE)\n",
    "def random_weight():\n",
    "    return uniform(-0.5, 0.5)\n",
    "\n",
    "def create_network_topology(num_inputs, num_hidden, num_output):\n",
    "    # Let's represent the network as a dictionary. \n",
    "    # Remember that training a network is about learning the weights values. So we will eventually store weights in this dictionary.\n",
    "    # - There are weights from the input layer to the hidden layer (therefore,  dictionary should have a high level \"hidden\" key).\n",
    "    # - There are weights from the hidden layer to the output layer (therefore,  dictionary should have a high level \"output\" key).\n",
    "\n",
    "    # The parent dictionary\n",
    "    neural_net = {}\n",
    "    # Create a dictionary that will hold all hidden layer nodes\n",
    "    hidden_layer = {}\n",
    "    # Create a dictionary that will hold all output layer nodes\n",
    "    output_layer = {}\n",
    "    \n",
    "    for i in range(num_hidden):\n",
    "        node_name = \"H\" + str(i + 1)\n",
    "        weights_list = []\n",
    "\n",
    "        # Intialize all weights feeding into hidden node to random values (the 1 is for the additional bias weight w0)\n",
    "        for j in range(num_inputs):\n",
    "            weights_list.append(random_weight())\n",
    "            \n",
    "        hidden_layer[node_name] = np.array(object=weights_list,dtype=float)\n",
    "\n",
    "    # Add hidden layer to parent dictionary\n",
    "    neural_net[\"hidden\"] = hidden_layer\n",
    "\n",
    "    for i in range(num_output):\n",
    "        node_name = \"O\" + str(i + 1)\n",
    "        weights_list = []\n",
    "\n",
    "        # Intialize all weights feeding into output node to random values (the 1 is for the additional bias weight w0)\n",
    "        for j in range(num_hidden ):\n",
    "            weights_list.append(random_weight())\n",
    "\n",
    "        output_layer[node_name] = np.array(object=weights_list,dtype=float)\n",
    "\n",
    "    # Add output layer to parent dictionary\n",
    "    neural_net[\"output\"] = output_layer\n",
    "\n",
    "    return neural_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"squash\" output value\n",
    "def sigmoid(x):\n",
    "    # Prevent overflow by clipping extreme values\n",
    "    x = np.clip(x, -500, 500)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "def mpropegate_forward(image, network):\n",
    "   \n",
    "    #calculate hidden outputs after sigmoid:\n",
    "    H1 = sigmoid((image*network[\"hidden\"][\"H1\"]).sum()+1)\n",
    "    H2 = sigmoid((image*network[\"hidden\"][\"H2\"]).sum()+1)\n",
    "    H3 = sigmoid((image*network[\"hidden\"][\"H3\"]).sum()+1)\n",
    "    H4 = sigmoid((image*network[\"hidden\"][\"H4\"]).sum()+1)\n",
    "    H5 = sigmoid((image*network[\"hidden\"][\"H5\"]).sum()+1)\n",
    "    H6 = sigmoid((image*network[\"hidden\"][\"H6\"]).sum()+1)\n",
    "    H7 = sigmoid((image*network[\"hidden\"][\"H7\"]).sum()+1)\n",
    "    H8 = sigmoid((image*network[\"hidden\"][\"H8\"]).sum()+1)\n",
    "    H9 = sigmoid((image*network[\"hidden\"][\"H9\"]).sum()+1)\n",
    "    H10 = sigmoid((image*network[\"hidden\"][\"H10\"]).sum()+1)\n",
    "    H11 = sigmoid((image*network[\"hidden\"][\"H11\"]).sum()+1)\n",
    "    H12 = sigmoid((image*network[\"hidden\"][\"H12\"]).sum()+1)\n",
    "    H13 = sigmoid((image*network[\"hidden\"][\"H13\"]).sum()+1)\n",
    "    H14 = sigmoid((image*network[\"hidden\"][\"H14\"]).sum()+1)\n",
    "    H15 = sigmoid((image*network[\"hidden\"][\"H15\"]).sum()+1)\n",
    "    H16 = sigmoid((image*network[\"hidden\"][\"H16\"]).sum()+1)\n",
    "    image_mid = np.array([H1, H2, H3, H4, H5, H6, H7, H8, H9, H10, H11, H12, H13, H14, H15, H16])\n",
    "        \n",
    "    #calculate output values after sigmoid   \n",
    "    O1 = sigmoid((image_mid*network[\"output\"][\"O1\"]).sum()+1)\n",
    "    O2 = sigmoid((image_mid*network[\"output\"][\"O2\"]).sum()+1)\n",
    "    O3 = sigmoid((image_mid*network[\"output\"][\"O3\"]).sum()+1)\n",
    "    O4 = sigmoid((image_mid*network[\"output\"][\"O4\"]).sum()+1)\n",
    "    O5 = sigmoid((image_mid*network[\"output\"][\"O5\"]).sum()+1)\n",
    "    O6 = sigmoid((image_mid*network[\"output\"][\"O6\"]).sum()+1)\n",
    "    O7 = sigmoid((image_mid*network[\"output\"][\"O7\"]).sum()+1)\n",
    "    O8 = sigmoid((image_mid*network[\"output\"][\"O8\"]).sum()+1)\n",
    "    O9 = sigmoid((image_mid*network[\"output\"][\"O9\"]).sum()+1)\n",
    "    O10 = sigmoid((image_mid*network[\"output\"][\"O10\"]).sum()+1)\n",
    "    image_out = np.array([O1, O2, O3, O4, O5, O6, O7, O8, O9, O10])\n",
    "   \n",
    "    #returns data needed for propegate_backwards function\n",
    "    data = np.array([image_mid, image_out])\n",
    "    return data\n",
    "\n",
    "\n",
    "def propegate_back(output, network, expected, image, learning_rate):\n",
    "\n",
    "    #calculate output error\n",
    "    EO0 = output[1][0] * (1-output[1][0])*(expected[0]-output[1][0])\n",
    "    EO1 = output[1][1] * (1-output[1][1])*(expected[1]-output[1][1])\n",
    "    EO2 = output[1][2] * (1-output[1][2])*(expected[2]-output[1][2])\n",
    "    EO3 = output[1][3] * (1-output[1][3])*(expected[3]-output[1][3])\n",
    "    EO4 = output[1][4] * (1-output[1][4])*(expected[4]-output[1][4])\n",
    "    EO5 = output[1][5] * (1-output[1][5])*(expected[5]-output[1][5])\n",
    "    EO6 = output[1][6] * (1-output[1][6])*(expected[6]-output[1][6])\n",
    "    EO7 = output[1][7] * (1-output[1][7])*(expected[7]-output[1][7])\n",
    "    EO8 = output[1][8] * (1-output[1][8])*(expected[8]-output[1][8])\n",
    "    EO9 = output[1][9] * (1-output[1][9])*(expected[9]-output[1][9])\n",
    "    output_error = np.array([EO0, EO1, EO2, EO3, EO4, EO5, EO6, EO7, EO8, EO9])\n",
    "    \n",
    "    # CRITICAL FIX: INITIALIZE hidden errors to zero before accumulation\n",
    "    EH1 = EH2 = EH3 = EH4 = EH5 = EH6 = EH7 = EH8 = 0.0\n",
    "    EH9 = EH10 = EH11 = EH12 = EH13 = EH14 = EH15 = EH16 = 0.0\n",
    "    \n",
    "    #calculate hidden error - now properly accumulating\n",
    "    for i in range(10):\n",
    "        EH1 += network[\"output\"][\"O\"+str(i+1)][0]*output_error[i]\n",
    "        EH2 += network[\"output\"][\"O\"+str(i+1)][1]*output_error[i]\n",
    "        EH3 += network[\"output\"][\"O\"+str(i+1)][2]*output_error[i]\n",
    "        EH4 += network[\"output\"][\"O\"+str(i+1)][3]*output_error[i]\n",
    "        EH5 += network[\"output\"][\"O\"+str(i+1)][4]*output_error[i]\n",
    "        EH6 += network[\"output\"][\"O\"+str(i+1)][5]*output_error[i]\n",
    "        EH7 += network[\"output\"][\"O\"+str(i+1)][6]*output_error[i]\n",
    "        EH8 += network[\"output\"][\"O\"+str(i+1)][7]*output_error[i]\n",
    "        EH9 += network[\"output\"][\"O\"+str(i+1)][8]*output_error[i]\n",
    "        EH10 += network[\"output\"][\"O\"+str(i+1)][9]*output_error[i]\n",
    "        EH11 += network[\"output\"][\"O\"+str(i+1)][10]*output_error[i]\n",
    "        EH12 += network[\"output\"][\"O\"+str(i+1)][11]*output_error[i]\n",
    "        EH13 += network[\"output\"][\"O\"+str(i+1)][12]*output_error[i]\n",
    "        EH14 += network[\"output\"][\"O\"+str(i+1)][13]*output_error[i]\n",
    "        EH15 += network[\"output\"][\"O\"+str(i+1)][14]*output_error[i]\n",
    "        EH16 += network[\"output\"][\"O\"+str(i+1)][15]*output_error[i]\n",
    "    \n",
    "    # CRITICAL FIX: Apply sigmoid derivative to hidden errors\n",
    "    EH1 *= output[0][0] * (1 - output[0][0])\n",
    "    EH2 *= output[0][1] * (1 - output[0][1])\n",
    "    EH3 *= output[0][2] * (1 - output[0][2])\n",
    "    EH4 *= output[0][3] * (1 - output[0][3])\n",
    "    EH5 *= output[0][4] * (1 - output[0][4])\n",
    "    EH6 *= output[0][5] * (1 - output[0][5])\n",
    "    EH7 *= output[0][6] * (1 - output[0][6])\n",
    "    EH8 *= output[0][7] * (1 - output[0][7])\n",
    "    EH9 *= output[0][8] * (1 - output[0][8])\n",
    "    EH10 *= output[0][9] * (1 - output[0][9])\n",
    "    EH11 *= output[0][10] * (1 - output[0][10])\n",
    "    EH12 *= output[0][11] * (1 - output[0][11])\n",
    "    EH13 *= output[0][12] * (1 - output[0][12])\n",
    "    EH14 *= output[0][13] * (1 - output[0][13])\n",
    "    EH15 *= output[0][14] * (1 - output[0][14])\n",
    "    EH16 *= output[0][15] * (1 - output[0][15])\n",
    "    \n",
    "    hidden_error = [EH1, EH2, EH3, EH4, EH5, EH6, EH7, EH8, EH9, EH10, EH11, EH12, EH13, EH14, EH15, EH16]\n",
    "    \n",
    "    # CRITICAL FIX: Corrected index error - changed output_error[j-1] to output_error[j]\n",
    "    for j in range(10):\n",
    "        for i in range (16):\n",
    "            network[\"output\"][\"O\"+str(j+1)][i] = network[\"output\"][\"O\"+str(j+1)][i] + learning_rate * output_error[j] * output[0][i]\n",
    "    for i in range (16):\n",
    "        for j in range (784):\n",
    "            network[\"hidden\"][\"H\" + str(i+1)][j] = network[\"hidden\"][\"H\" + str(i+1)][j] + learning_rate * hidden_error[i] * image[j]\n",
    "    return network\n",
    "\n",
    "#this method uses the testing array and testing labels array to check the accuracy of the model\n",
    "def test_accuracy(network, testing_array):\n",
    "    correct = 0\n",
    "    #iterate through entire testing array (10,000)\n",
    "    for i in range(500):#testing_array.shape[0]):\n",
    "        output = mpropegate_forward(testing_array[i], network) #propegate forward with one image and the network\n",
    "        output_index = int(np.argmax(output[1]))\n",
    "        expected = int(testing_labels[i])\n",
    "        if output_index == expected: #check that vector representation of target has same max index as vector representation of output from trained model\n",
    "            #if it matches add to the counter\n",
    "            correct = correct + 1\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute the training of the data\n",
    "\n",
    "#first let's define some parameters - IMPROVED PARAMETERS\n",
    "learning_rate = 0.1  # Increased from 0.005\n",
    "epoch = 5            # Increased from 3\n",
    "hidden_layers = 16\n",
    "inputs = 784\n",
    "outputs = 10\n",
    "correct = 0\n",
    "\n",
    "#create a network once which will be updated as data is processed\n",
    "network = create_network_topology(inputs,hidden_layers,outputs)\n",
    "\n",
    "#start a clock to time program\n",
    "start = timeit.default_timer()\n",
    "#execute all steps once for each epoch (loop)\n",
    "for i in range(epoch):\n",
    "    print(f\"Starting epoch {i+1}/{epoch}\")\n",
    "    \n",
    "    #propegate forwards and backwards for each image to train model using entire training_array\n",
    "    for j in range(5000):#training_array.shape[0]): # Increased from 1000\n",
    "        output12 = mpropegate_forward(training_array[j], network)\n",
    "        output = output12[1] #vector for output of given image\n",
    "        target_int = int(training_labels[j]) #actual integer value of target according to training data\n",
    "        expected = actual[target_int] # vector representation of target value\n",
    "        network = propegate_back(output12, network, expected, training_array[j], learning_rate) # FIXED: added learning_rate parameter\n",
    "        \n",
    "print(\"training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model for accuracy once training loop is complete by counting correct results\n",
    "correct = correct + test_accuracy(network, testing_array)\n",
    "end = timeit.default_timer() #stop the clock\n",
    "\n",
    "#show my results\n",
    "print(\"RESULTS:\", \"\\n\")\n",
    "print(\"Network properties: Input: 784, Hidden: 16, Output: 10\")  # Fixed display\n",
    "print(\"Learning rate: \", learning_rate)\n",
    "print(\"Epochs: \", epoch)\n",
    "print(\"Training samples per epoch: 5000\")\n",
    "\n",
    "test_size = 500  # We're only testing on 500 samples\n",
    "accuracy = correct / test_size\n",
    "incorrect = test_size - correct\n",
    "\n",
    "print(\"Correct Classification = \", correct)\n",
    "print(\"Incorrect Classification = \", incorrect)\n",
    "print(\"Accuracy = \", accuracy)\n",
    "print(\"Duration: \", (end-start)/60, \"minutes\")\n",
    "print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
